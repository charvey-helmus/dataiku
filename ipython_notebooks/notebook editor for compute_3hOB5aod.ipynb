{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-mlflow-cpu-4-ram32gb",
      "display_name": "Python in CPU-4-RAM32Gb (env mlflow)",
      "language": "python"
    },
    "associatedRecipe": "compute_3hOB5aod",
    "creator": "chris.helmus@dataiku.com",
    "createdOn": 1668099364331,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "modifiedBy": "chris.helmus@dataiku.com",
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd, numpy as np"
      ],
      "outputs": []
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score"
      ],
      "outputs": []
    },
    {
      "execution_count": 11,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load \u0027train\u0027 dataset as a Pandas dataframe\ndf \u003d dataiku.Dataset(\"flight_data\").get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 12,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Dataset Settings\n#-----------------------------------------------------------------\n\n# Select a subset of features to use for training\nSCHEMA \u003d {\n    \u0027target\u0027: \u0027Late\u0027,\n    \u0027features_num\u0027: [\u0027dep_month\u0027, \u0027dep_woy\u0027, \u0027dep_hour\u0027,\u0027Distance\u0027,\u0027Late_avg\u0027],\n    \u0027features_cat\u0027: [\u0027UniqueCarrier\u0027, \u0027Origin\u0027,\u0027Dest\u0027]\n}"
      ],
      "outputs": []
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Preprocessing on Training Set\n#-----------------------------------------------------------------\n\n# Numerical variables\ndf_num \u003d df[SCHEMA[\u0027features_num\u0027]]\n\ntrf_num \u003d Pipeline([\n    (\u0027imp\u0027, SimpleImputer(strategy\u003d\u0027mean\u0027)),\n    (\u0027sts\u0027, StandardScaler()),\n])\n\n# Categorical variables\ndf_cat \u003d df[SCHEMA[\u0027features_cat\u0027]]\n\ntrf_cat \u003d OneHotEncoder(handle_unknown\u003d\"ignore\")\n\npreprocessor \u003d ColumnTransformer(\n    transformers\u003d[\n        (\"num\", trf_num, SCHEMA[\u0027features_num\u0027]),\n        (\"cat\", trf_cat, SCHEMA[\u0027features_cat\u0027])\n    ]\n)"
      ],
      "outputs": []
    },
    {
      "execution_count": 24,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-------------------------------------------------------------------------\n# TRAINING\n#-------------------------------------------------------------------------\n##### TO-DO: add experiment tracking code here\n##### but watch out for lineage (don\u0027t use the deploy button from the xperiment tracking UI)\nimport dataiku\nimport mlflow\nfrom sklearn.linear_model import ElasticNet\n\nclient \u003d dataiku.api_client()\nproject \u003d client.get_project(dataiku.default_project_key())\n\n# Setup mlflow integration, storing artefacts in managed folder. Managed folder must already exist.\nmlflow_handle \u003d project.setup_mlflow(\u00273hOB5aod\u0027)\n\n# MLflow run and experiment will be sent to DSS backend.\nmlflow.set_experiment(\"sample autolog\")\n\n# activate Mflow autologging\nmlflow.sklearn.autolog()\n\nwith mlflow.start_run(run_name\u003d\"my_run\"):\n    clf \u003d Pipeline(\n        steps\u003d[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())]\n    )\n\n    param_grid \u003d {\n        \"clf__max_depth\"        : [3],\n        \"clf__max_features\"     : [1],\n        \"clf__min_samples_split\": [2],\n        \"clf__min_samples_leaf\" : [1],\n        \"clf__bootstrap\"        : [False],\n            \"clf__criterion\"        : [\"gini\"],\n    \"clf__n_estimators\"     : [10]\n    }\n\n    gs \u003d GridSearchCV(clf, param_grid\u003dparam_grid, n_jobs\u003d-1, scoring\u003d\u0027roc_auc\u0027, cv\u003d3)\n    X \u003d df[SCHEMA[\u0027features_num\u0027] + SCHEMA[\u0027features_cat\u0027]]\n    Y \u003d df[SCHEMA[\u0027target\u0027]].values\n    gs.fit(X, Y)\n    clf \u003d gs.best_estimator_"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "2022/11/10 21:10:56 INFO mlflow.tracking.fluent: Experiment with name \u0027sample autolog\u0027 does not exist. Creating a new experiment.\n2022/11/10 21:10:56 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n2022/11/10 21:10:57 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(steps\u003d[(\u0027preprocessor\u0027,\n                 ColumnTransformer(transformers\u003d[(\u0027num\u0027,\n                                                  Pipeline(steps\u003d[(\u0027imp\u0027,\n                                                                   SimpleImputer()),\n                                                                  (\u0027sts\u0027,\n                                                                   StandardScaler())]),\n                                                  [\u0027dep_month\u0027, \u0027dep_woy\u0027,\n           ...`\n/opt/dataiku/code-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n2022/11/10 21:11:03 WARNING mlflow.sklearn.utils: Failed to import matplotlib (error: ModuleNotFoundError(\"No module named \u0027matplotlib\u0027\")). Skipping artifact logging.\n2022/11/10 21:11:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/dataiku/code-env/lib/python3.8/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\"\n2022/11/10 21:11:12 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n2022/11/10 21:11:12 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[(\u0027preprocessor\u0027, ColumnTransformer(transformers\u003d[(\u0027num\u0027,\n                                 Pipeline(steps\u003d[(\u0027imp\u0027, SimpleImputer()),\n                                                 (\u0027sts\u0027, StandardScaler())]),\n                                 [\u0027dep_month\u0027, \u0027dep_woy\u0027, \u0027dep_hour\u0027,\n                                  \u0027Distance\u0027, \u0027Late_avg\u0027]),\n                                (\u0027cat\u0027, OneHotEncoder(handle_unknown\u003d\u0027ignore\u0027),\n                                 [\u0027UniqueCarrier\u0027, \u0027Origin\u0027, \u0027Dest\u0027])])), (\u0027...`\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 21,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "{\u0027projectKey\u0027: \u0027MLFLOWO16N\u0027,\n \u0027directoryBasedPartitioning\u0027: False,\n \u0027name\u0027: \u0027my_pkl_model\u0027,\n \u0027id\u0027: \u00273hOB5aod\u0027,\n \u0027accessInfo\u0027: {\u0027bucket\u0027: \u0027gis-data-us-east-1\u0027,\n  \u0027root\u0027: \u0027/space-5b568791-dku/node-0874aa03/managed-dss-data/MLFLOWO16N/3hOB5aod\u0027},\n \u0027type\u0027: \u0027S3\u0027}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlflow"
      ],
      "outputs": []
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mlflow.sklearn.save_model(clf, mlflow_models)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:botocore.credentials:Refreshing temporary credentials failed during mandatory refresh period.\nTraceback (most recent call last):\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 570, in _protected_refresh\n    metadata \u003d self._refresh_using()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 717, in fetch_credentials\n    return self._get_cached_credentials()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 727, in _get_cached_credentials\n    response \u003d self._get_credentials()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 956, in _get_credentials\n    kwargs \u003d self._assume_role_kwargs()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 966, in _assume_role_kwargs\n    identity_token \u003d self._web_identity_token_loader()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/utils.py\", line 3069, in __call__\n    with self._open(self._web_identity_token_path) as token_file:\nFileNotFoundError: [Errno 2] No such file or directory: \u0027/var/run/secrets/eks.amazonaws.com/serviceaccount/token\u0027\n2022/11/10 21:05:23 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: s3://gis-data-us-east-1/space-5b568791-dku/node-0874aa03/managed-dss-data/MLFLOWO16N/3hOB5aod/model.pkl, flavor: sklearn), fall back to return [\u0027scikit-learn\u003d\u003d1.1.3\u0027, \u0027cloudpickle\u003d\u003d2.2.0\u0027]. Set logging level to DEBUG to see the full traceback.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 12,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Save models as mlflow models to a folder\nfrom datetime import datetime\nimport os\nts \u003d datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nmodel_dir \u003d mlflow_models + \"/custom-random-forest-{}\".format(ts)\nmlflow.sklearn.save_model(clf, model_dir)\nprint(\"Model saved at {} !\".format(os.path.abspath(model_dir)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:botocore.credentials:Refreshing temporary credentials failed during mandatory refresh period.\nTraceback (most recent call last):\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 570, in _protected_refresh\n    metadata \u003d self._refresh_using()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 717, in fetch_credentials\n    return self._get_cached_credentials()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 727, in _get_cached_credentials\n    response \u003d self._get_credentials()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 956, in _get_credentials\n    kwargs \u003d self._assume_role_kwargs()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/credentials.py\", line 966, in _assume_role_kwargs\n    identity_token \u003d self._web_identity_token_loader()\n  File \"/opt/dataiku/code-env/lib/python3.8/site-packages/botocore/utils.py\", line 3069, in __call__\n    with self._open(self._web_identity_token_path) as token_file:\nFileNotFoundError: [Errno 2] No such file or directory: \u0027/var/run/secrets/eks.amazonaws.com/serviceaccount/token\u0027\n2022/11/10 20:26:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: s3://gis-data-us-east-1/space-5b568791-dku/node-0874aa03/managed-dss-data/MLFLOWO16N/3hOB5aod/custom-random-forest-20221110-202652/model.pkl, flavor: sklearn), fall back to return [\u0027scikit-learn\u003d\u003d1.1.3\u0027, \u0027cloudpickle\u003d\u003d2.2.0\u0027]. Set logging level to DEBUG to see the full traceback.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Model saved at /home/dataiku/s3:/gis-data-us-east-1/space-5b568791-dku/node-0874aa03/managed-dss-data/MLFLOWO16N/3hOB5aod/custom-random-forest-20221110-202652 !\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataikuapi\nimport dataiku\n\nclient \u003d dataiku.api_client()\nproject \u003d client.get_default_project()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 16,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n#Â Get or create saved models\nif dataiku.get_custom_variables()[\"saved_model_id\"] \u003d\u003d \"\":\n    saved_model \u003d project.create_mlflow_pyfunc_model(\"mlflow_model\", \"BINARY_CLASSIFICATION\")\n    project.update_variables({\"saved_model_id\": saved_model.id})\nelse:\n    saved_model \u003d project.get_saved_model(dataiku.get_custom_variables()[\"saved_model_id\"])\nsaved_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "\u003cdataikuapi.dss.savedmodel.DSSSavedModel at 0x7f84cb5bd250\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\nmlflow_version \u003d saved_model.import_mlflow_version_from_path(dataiku.get_custom_variables()[\"custom_model_version\"], model_dir, code_env_name\u003d\"mlflow\")\nproject.update_variables({\"custom_model_version\": int(dataiku.get_custom_variables()[\"custom_model_version\"]) + 1})"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataikuException",
          "evalue": "com.dataiku.dip.server.controllers.NotFoundException: saved model does not exist: MLFLOWO16N.AwjDsbSf",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/opt/dataiku/python/dataikuapi/dssclient.py\u001b[0m in \u001b[0;36m_perform_http\u001b[0;34m(self, method, path, params, body, stream, files, raw_body, headers)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                     headers\u003dheaders)\n\u001b[0;32m-\u003e 1234\u001b[0;31m             \u001b[0mhttp_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhttp_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/code-env/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://dss-headless-node-0874aa03.space-5b568791-dku.svc.cluster.local:44001/dip/publicapi/projects/MLFLOWO16N/savedmodels/AwjDsbSf/versions/1?codeEnvName\u003dmlflow\u0026containerExecConfigName\u003dINHERIT",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDataikuException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-17-2abaf4178aba\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmlflow_version\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_mlflow_version_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiku\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_custom_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"custom_model_version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_env_name\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\"mlflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"custom_model_version\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiku\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_custom_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"custom_model_version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/python/dataikuapi/dss/savedmodel.py\u001b[0m in \u001b[0;36mimport_mlflow_version_from_path\u001b[0;34m(self, version_id, path, code_env_name, container_exec_config_name)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 151\u001b[0;31m                 self.client._perform_empty(\"POST\", \"/projects/%s/savedmodels/%s/versions/%s?codeEnvName\u003d%s\u0026containerExecConfigName\u003d%s\" % (self.project_key, self.sm_id, version_id, code_env_name, container_exec_config_name),\n\u001b[0m\u001b[1;32m    152\u001b[0m                                            files\u003d{\"file\": (archive_filename, fp)})\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mlflow_version_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/python/dataikuapi/dssclient.py\u001b[0m in \u001b[0;36m_perform_empty\u001b[0;34m(self, method, path, params, body, files, raw_body)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_perform_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_body\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_perform_http\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_body\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mraw_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_perform_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_body\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/python/dataikuapi/dssclient.py\u001b[0m in \u001b[0;36m_perform_http\u001b[0;34m(self, method, path, params, body, stream, files, raw_body, headers)\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                 \u001b[0mex\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttp_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataikuException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"errorType\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unknown error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_perform_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_body\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDataikuException\u001b[0m: com.dataiku.dip.server.controllers.NotFoundException: saved model does not exist: MLFLOWO16N.AwjDsbSf"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mlflow_version.set_core_metadata(SCHEMA[\u0027target\u0027], class_labels\u003d[\"false\", \"true\"], get_features_from_dataset\u003d\"flight_ground_truth\")\nmlflow_version.evaluate(\"flight_ground_truth\")"
      ],
      "outputs": []
    }
  ]
}