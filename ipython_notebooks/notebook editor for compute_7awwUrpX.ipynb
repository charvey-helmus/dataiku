{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-mlflow-cpu-m-1-cpu-4gb-ram",
      "display_name": "Python in CPU-M-1-cpu-4Gb-Ram (env mlflow)",
      "language": "python"
    },
    "associatedRecipe": "compute_7awwUrpX",
    "creator": "chris.helmus@dataiku.com",
    "createdOn": 1673389196553,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "modifiedBy": "chris.helmus@dataiku.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\n# Read recipe inputs\nmy_dataset \u003d dataiku.Dataset(\"flight_data_prepared\")\ndf \u003d my_dataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Dataset Settings\n#-----------------------------------------------------------------\n\n# Select a subset of features to use for training\nSCHEMA \u003d {\n    \u0027target\u0027: \u0027Late_avg\u0027,\n    \u0027features_num\u0027: [\u0027dep_month\u0027, \u0027dep_woy\u0027, \u0027dep_hour\u0027,\u0027Distance\u0027],\n    \u0027features_cat\u0027: [\u0027UniqueCarrier\u0027, \u0027Origin\u0027,\u0027Dest\u0027,\u0027Late\u0027]\n}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Preprocessing on Training Set\n#-----------------------------------------------------------------\n\n# Numerical variables\ndf_num \u003d df[SCHEMA[\u0027features_num\u0027]]\n\ntrf_num \u003d Pipeline([\n    (\u0027imp\u0027, SimpleImputer(strategy\u003d\u0027mean\u0027)),\n    (\u0027sts\u0027, StandardScaler()),\n])\n\n# Categorical variables\ndf_cat \u003d df[SCHEMA[\u0027features_cat\u0027]]\n\ntrf_cat \u003d OneHotEncoder(handle_unknown\u003d\"ignore\")\n\npreprocessor \u003d ColumnTransformer(\n    transformers\u003d[\n        (\"num\", trf_num, SCHEMA[\u0027features_num\u0027]),\n        (\"cat\", trf_cat, SCHEMA[\u0027features_cat\u0027])\n    ]\n)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport mlflow\n\n\nproject \u003d dataiku.api_client().get_default_project()\nmanaged_folder \u003d project.get_managed_folder(\u0027R47GTRDp\u0027)\nexperiment_name \u003d \"my_experiment\"\n\nwith project.setup_mlflow(managed_folder\u003dmanaged_folder) as mlflow:\n    mlflow.set_experiment(experiment_name)\n\n    # activate Mflow autologging\n    mlflow.sklearn.autolog()\n\n    with mlflow.start_run(run_name\u003d\"my_run\"):\n        clf \u003d Pipeline(steps\u003d[(\"preprocessor\", preprocessor), (\"clf\", RandomForestRegressor())])\n\n        param_grid \u003d {\n            \"clf__max_depth\"        : [3],\n            \"clf__max_features\"     : [1],\n            \"clf__min_samples_split\": [2],\n            \"clf__min_samples_leaf\" : [1],\n            \"clf__bootstrap\"        : [False],\n            \"clf__n_estimators\"     : [10]\n        }\n\n        gs \u003d GridSearchCV(clf, param_grid\u003dparam_grid, n_jobs\u003d-1, scoring\u003d\u0027neg_mean_absolute_error\u0027, cv\u003d3)\n        X \u003d df[SCHEMA[\u0027features_num\u0027] + SCHEMA[\u0027features_cat\u0027]]\n        #Y \u003d df[SCHEMA[\u0027target\u0027]].values\n        Y \u003d df[SCHEMA[\u0027target\u0027]]\n        gs.fit(X, Y)\n        clf \u003d gs.best_estimator_"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nproject \u003d client.get_project(\u0027MLFLOWCH\u0027)\n#Â Get or create saved models\nif dataiku.get_custom_variables()[\"saved_model_id\"] \u003d\u003d \"\":\n    saved_model \u003d project.create_mlflow_pyfunc_model(\"mlflow_model\", \"REGRESSION\")\n    project.update_variables({\"saved_model_id\": saved_model.id})\nelse:\n    saved_model \u003d project.get_saved_model(dataiku.get_custom_variables()[\"saved_model_id\"])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "experiment_folder \u003d dataiku.Folder(\"R47GTRDp\")\n#model_dir \u003d experiment_folder.get_path()+\"/my_experiment_tracking/my_experiment/my_run_mEN/artifacts/model/\"\nmodel_dir \u003d\"my_experiment/my_run_mEN/artifacts/model/\"\nmlflow_version \u003d saved_model.import_mlflow_version_from_managed_folder(dataiku.get_custom_variables()[\"custom_model_version\"], \"R47GTRDp\", model_dir,code_env_name\u003d\"python36\")\nproject.update_variables({\"custom_model_version\": int(dataiku.get_custom_variables()[\"custom_model_version\"]) + 1})"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mlflow_version.set_core_metadata(SCHEMA[\u0027target\u0027],get_features_from_dataset\u003d\"flight_ground_truth_prepared\")\nmlflow_version.evaluate(\"flight_ground_truth_prepared\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\ntest \u003d dataiku.Dataset(\"flight_ground_truth_prepared\")\ndf_2 \u003d test.get_dataframe()\ndf_2.describe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\u0027\u0027\u0027\n#extra testing to confirm if i can properly load file\nimport dataiku\nhandle \u003d dataiku.Folder(\"3hOB5aod\")\n# pass a partition identifier if the folder is partitioned\npaths \u003d handle.list_paths_in_partition()\npaths\n\nwith handle.get_download_stream(\"experiment_2/my_run_jHL/artifacts/model/conda.yaml\") as f:\n    data \u003d f.read()\n\noutput_handle \u003d dataiku.Folder(\"WISPen39\")\n\nwith output_handle.get_writer(\"output.yaml\") as w:\n    w.write(data)\n    \u0027\u0027\u0027"
      ],
      "outputs": []
    }
  ]
}